# RAG-Pipeline Project Skeleton

## Projektstruktur

```
ğŸ“ project_root/
â”œâ”€â”€ ğŸ“ api/                      # FastAPI REST API
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ main.py                  # API Endpoints
â”œâ”€â”€ ğŸ“ src/                      # Core Logic
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                # Configuration & Settings
â”‚   â”œâ”€â”€ models.py                # Pydantic Data Models
â”‚   â”œâ”€â”€ classifier.py            # Intent Classification
â”‚   â”œâ”€â”€ retriever.py             # Knowledge Retrieval (Vector DB)
â”‚   â”œâ”€â”€ generator.py             # LLM Response Generation
â”‚   â”œâ”€â”€ quality_check.py         # Response Quality Validation
â”‚   â”œâ”€â”€ answer_judge.py          # Answer Quality Scoring
â”‚   â”œâ”€â”€ pipeline.py              # Main Pipeline Orchestration
â”‚   â”œâ”€â”€ rate_limiter.py          # API Rate Limiting
â”‚   â””â”€â”€ utils.py                 # Helper Functions
â”œâ”€â”€ ğŸ“ data/
â”‚   â”œâ”€â”€ ğŸ“ knowledge_base/       # Source Documents
â”‚   â”‚   â””â”€â”€ faq.jsonl            # Knowledge Base (JSONL format)
â”‚   â””â”€â”€ ğŸ“ vector_db/            # FAISS Vector Store
â”‚       â”œâ”€â”€ index.faiss          # (generated)
â”‚       â””â”€â”€ index.pkl            # (generated)
â”œâ”€â”€ ğŸ“ logs/                     # Application Logs
â”œâ”€â”€ ğŸ“ deployment/               # Deployment Scripts
â”‚   â””â”€â”€ deploy.sh
â”œâ”€â”€ .env                         # Environment Variables
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

## Core Components

### 1. Configuration (`src/config.py`)
- Centralized settings using Pydantic BaseSettings
- Environment variable management
- API keys, model configs, paths

### 2. Data Models (`src/models.py`)
- Pydantic models for request/response validation
- Type safety across the pipeline
- Clear data contracts

### 3. Classifier (`src/classifier.py`)
- Intent classification using LLM
- Structured output (categories, confidence, reasoning)
- Decides routing logic

### 4. Retriever (`src/retriever.py`)
- Vector similarity search (FAISS)
- Loads knowledge base (JSONL)
- Returns top-k relevant documents

### 5. Generator (`src/generator.py`)
- LLM-based response generation
- Uses retrieved context + classification
- Structured prompts with guidelines

### 6. Quality Check (`src/quality_check.py`)
- Post-generation validation
- Checks: relevance, completeness, politeness, etc.
- Pass/fail + explanations

### 7. Answer Judge (`src/answer_judge.py`)
- Overall quality scoring (0-100)
- Weighted evaluation criteria
- Decision: accept/reject/manual_review

### 8. Pipeline (`src/pipeline.py`)
- Orchestrates all components
- Main `process(query)` method
- Returns complete result with metadata

### 9. API (`api/main.py`)
- FastAPI endpoints
- `/process` - full pipeline
- `/classify-only` - classification only
- Rate limiting, CORS, error handling

## Data Flow

```
User Query
    â†“
[Sanitize Input]
    â†“
[Classifier] â†’ Intent + Category + Confidence (optional)
    â†“
[Retriever] â†’ Top-K Relevant Docs (Vector Search)
    â†“
[Generator] â†’ LLM Response (with context)
    â†“
[Quality Check] â†’ Validation Checks incl. Answer Judge (optional)
    â†“
API Response (JSON)
```

Barebones Structure:

User Query
    â†“
Retreive
    â†“
Generate
    â†“
Response

## Key Patterns

1. **Modular Components**: Each step is isolated, testable
2. **Structured Outputs**: LLMs return JSON for reliability
3. **Multi-Stage Validation**: Classification â†’ Generation â†’ Quality â†’ Judging
4. **JSONL Knowledge Base**: Easy to update, one Q&A per line
5. **Vector Search**: Fast semantic retrieval with FAISS
6. **Rate Limiting**: Protect API from abuse
7. **Environment Config**: Secrets in .env, never committed

## Technology Stack

- **Framework**: FastAPI
- **LLM**: OpenAI (GPT-4/3.5)
- **Embeddings**: OpenAI text-embedding-3-small
- **Vector DB**: FAISS (in-memory)
- **Validation**: Pydantic
- **Orchestration**: LangChain (optional)
- **Deployment**: Docker

## Environment Variables (.env)

```
OPENAI_API_KEY=your_api_key_here
# Optional: Azure Blob Storage for knowledge base
BLOB_CONNECTION_STRING=your_connection_string
BLOB_CONTAINER_NAME=your_container
```

## Usage Pattern

```python
# Initialize Pipeline
pipeline = CustomerSupportPipeline()

# Process Query
result = pipeline.process("Where is my order?")

# Returns:
{
    "classification": {...},
    "retrieved_docs": [...],
    "answer": "...",
    "quality_checks": {...},
    "quality_score": 92,
    "decision": "accept",
    "processing_time_ms": 1234
}
```
